# ğŸš— Virtual Autonomous Car (VAC)

An AI-powered simulation of a self-driving car that can detect lanes, recognize objects, explain its driving decisions using traffic rules, and interact via a natural language interface.

---

## ğŸ“¦ Features

| Module | Description |
|--------|-------------|
| ğŸ›£ï¸ **Lane Detection** | Detects lane markings using OpenCV (Canny + Hough Transform). |
| ğŸš¦ **Object Detection** | Detects pedestrians, vehicles, and signals using YOLOv8. |
| ğŸ§  **Decision Engine** | Applies rules to decide actions (e.g., brake if pedestrian detected). |
| ğŸ“š **RAG Assistant** | Uses LangChain + ChromaDB to answer questions about the trip using traffic rules and logs. |
| ğŸ§¾ **Trip Logger** | Logs lane loss, detected objects, and system actions to CSV. |
| ğŸ–¼ï¸ **Gradio Dashboard** | Upload videos, preview detection, and ask questions like â€œWhy did the car slow down?â€ |

---

## ğŸ§  Tech Stack

- **Python**, **OpenCV**, **YOLOv8**
- **LangChain** + **ChromaDB**
- **Gradio** for interactive UI
- **Google Colab** for rapid prototyping
- Optional: **Streamlit** or **HuggingFace Spaces** for deployment

---

## ğŸš€ Quick Start (Colab Recommended)

1. Clone the repo or open in Google Colab.
2. Upload a driving video (e.g., `solidWhiteRight.mp4`)
3. Run detection cells to generate outputs.
4. Launch the Gradio interface to:
   - Preview processed frames
   - Upload custom videos
   - Ask natural language questions about decisions

---

## ğŸ¤– Example Questions You Can Ask

- *Why did the car slow down between frame 30â€“60?*
- *Was any pedestrian detected during the trip?*
- *Did the car lose lane tracking at any point?*

---

## ğŸ“‚ Project Structure

